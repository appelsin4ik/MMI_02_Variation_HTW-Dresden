# Multimodale Mensch-Maschine-Interaktion

Bearbeiter: Kyrylo Kozhemiakin

## Quellen

### Two-Step Gaze Guidance

Die Studie von Tifany C.K. Kwok et al. (2022) zum "Two-Step Gaze Guidance-System" untersucht, wie die Kombination aus Audio- und haptischen Signalen die Effizienz bei Suchaufgaben steigern kann. In einem zweistufigen Ansatz werden Nutzer zunächst durch räumliches Audio oder Vibrationen grob in die richtige Richtung gelenkt. Danach führt eine feinere Orientierung mithilfe von präziseren Audio- oder haptischen Signalen zum Ziel. In einer Laborstudie mit 69 Teilnehmern erwies sich die Nutzung von räumlichem Audio in der ersten Stufe als besonders effektiv und wurde von den Nutzern als intuitiver und hilfreicher wahrgenommen als das haptische Feedback. Als Fazit der Studie kann man sagen, dass räumliches Audio  deutliche Vorteile bei der Blickführung bietet und wird daher als bevorzugtes Mittel in der ersten Stufe empfohlen, da es die Zielsuche beschleunigt und die Benutzerfreundlichkeit erhöht.

![Abbildung einer multimodalen Interaktion mit Blick und ...](img/Heading_Picture_x3.png)

### GlassBoARd: A Gaze-Enabled AR Interface for Collaborative Work

Die Studie von Jannis Strecker et al. (2024) stellt GlassBoARd vor, ein AR-System, das Blickverfolgung und Avatare nutzt, um virtuelle Zusammenarbeit zu verbessern. Eine transparente Oberfläche ermöglicht natürlichen Blickkontakt, da die Augenbewegungen der Avatare den Nutzern entsprechen. Nach drei Entwicklungsstufen, in denen Funktionalität und Benutzerfreundlichkeit optimiert wurden, wurde das System erfolgreich in Tests eingesetzt. Es reduziert verbalen Aufwand und stärkt nonverbale Kommunikation. Zukünftig soll GlassBoARd vollständig AR-basiert werden, um Präsenz und Effizienz in realen Arbeitsprozessen weiter zu verbessern.Al Fazit kann man sagen, dass GlassBoARd das Potenzial von AR-Systemen zeigt, wie nonverbale Kommunikation effektiv zu nutzen und wie die virtuelle Zusammenarbeit natürlicher und effizienter zu gestalten ist. Es bietet eine Grundlage für zukünftige Forschungen und Anwendungen in realen Arbeitsumgebungen.

## Erweiterung und Variation

| | Two-Step Gaze Guiadance | GlassBoARd: A Gaze-Enabled AR Interface for Collaborative Work |
| --- | ---- | --- |
| Audiosignal | genau bei dem Zielobject | infromiert über den hergestellten Blickkontakt
| Vibration | auf der rechten oder linken Seite | _wenn der Nutzer vom vorgesehenen Arbeitsablauf abweicht_
| _Sprache_ | _es können sämtliche Nutzungsfragen von dem Nutzer gestellt werden, welche das System annimmt und mithilfe von KI verarbeitet,um eine Reaktion in Form eines Audiosignals auszusprechen_ | _kann für das Steuern des Systems via verbale Anweisungen eingesetzt werden_

![Abbildung des CARE-Modells](img/care_model_sprache.png)

## Storytelling for Design

### CROW-Framework

| Dimension    | Description |
| ------------ | ----------- |
| Character    | der Nutzer möchte sich nach dem anstrengenden Tag auf der Arbeit entspannen. Er ist technikaffin und bevorzugt komfortable Nutzung des Internets und der Unterhaltungssysteme. Leider gibt es bei ihm in der Wohnung keinen Fernseher. An Erfahrung mit solchen Technologien mangelt es bei ihm, findet aber hilfreich, wenn man Feedback mithilfe von Vibrationen bekommt. Die Verwaltung der Nutzeroberflächen mithilfe von Eye-Tracker hat er selten gesehen und empfindet dieses als atemberaubend und innovativ. Die praktische und innovative Nutzung des Geräts erweist sich auch in der sprachlichen Suche des Inhalts. Ebenfalls ein wichtiges Merkmal ist, das der Nutzer IOS-Systeme bevorzugt.    |
| Relationship | die Interaktion zwischen Mensch und Gerät zeigt sich in der reibungslosen Nutzung der verschiedenen Funktionen von dem Gerät (Apple Vision). Mithilfe von Eye-Tracking wählt der Nutzer gewünschte Bereiche in der Benutzeroberfläche aus, wobei haptisches Feedback durch Vibrationen die Eingabe bestätigt. Zusätzlich wird die Bedienung durch Sprachsteuerung ergänzt, die eine präzise und benutzerfreundliche Steuerung ermöglicht. Diese Art der Interaktion verdeutlicht, wie sehr sich der Nutzer auf die Effizienz und Funktionalität der Technologie verlässt.      |
| Objective    | das Hauptziel des Nutzers ist es, sich zu entspannen und einen Film zu genießen, obwohl er keinen Fernseher besitzt. Apple Vision bietet ihm genau diese Möglichkeit, indem es ein projiziertes Display nutzt und eine einfache Steuerung bereitstellt, die den Prozess komfortabel gestaltet.       |
| Where        | der Nutzer befindet sich in einem schlichten, privat eingerichteten Wohnzimmer, das ihm eine ruhige Umgebung bietet. In dieser entspannten Atmosphäre kann er die Funktionen des Geräts ungestört nutzen .      |

### Storyboarding

![KONZEPTION](img/mmi_03_konzeption_fertig_v2.png)

## Literaturverzeichnis

Tiffany C.K. Kwok, Peter Kiefer, and Martin Raubal. 2022. Two-Step Gaze Guidance. In Proceedings of 
the 2022 International Conference on Multimodal Interaction (ICMI '22). Association for Computing 
Machinery, New York, NY, USA, 299–309.
https://doi.org/10.1145/3536221.3556612

Kenan Bektaş, Adrian Pandjaitan, Jannis Strecker, and Simon Mayer. 2024. GlassBoARd: A Gaze-Enabled AR Interface for Collaborative Work. In Extended Abstracts of the CHI Conference on Human Factors in Computing Systems (CHI EA '24). Association for Computing Machinery, New York, NY, USA, Article 181, 1–8. 
https://doi.org/10.1145/3613905.3650965




